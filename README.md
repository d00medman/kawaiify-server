### Kawaiify Server

This README will primarily be concerned with elements specific to the back end of my product; the image manipulation system, the schema and database access and the infrastructure on which the whole app was deployed. An explanation of the broad functionality of the app can be found in the writeup for the client. All of that functionality is handled by routes in the `main.py` file. I elected to write the server in python for two reasons; 1.) because I appreciate the simplicity of flask and 2.) because python is so prominent in modern AI, the app serving the algorithms would be best written in the most popular language to better facilitate interoperability.

I kept the data schema of this application deliberately simple. There is currently only one table (images), which is primarily important for storing the files name, location and creator. There are two clear directions in which expansion can be made here. First, a more robust user functionality can be implemented. While the create and mutate routes are successfully guarded by auth0, there is no internal user system beyond the storing of email addresses associated with the image. Second would be the creation of a custom effects table, which would tie into the broader feature of adding custom effects; a considerable expansion which I felt to be beyond the scope of this project. Initially, I did DB access using the SQLAlchemy ORM. I switched over to using the psycopg2 library because I have a strong preference for using raw SQL (on readability grounds, displaying the query actually being run makes for large files, but those files are far easier to understand).

The image manipulation and the effects present are largely artifacts of my own experimentation. I first worked on embedding a simple manipulation; making an images shape circular. This allowed me to stand the project up initially and acted as a placeholdere while the outline was put in place. This effect was vital in establishing a pattern for how to manipulate and save images using numpy and the Python imaging library. Once this was viable, I turned my attention to the main effects, the sparkles and googly eyes. I started with the sparkles, with the goal of having an application which could target faces. I initally found the HAAR algorithm, and implemented this. HAAR, however, has some serious limitations, as I learned after more research. Given my time limitations, I elected to simply plug in openCV's prebuilt DNN for facial recognition. Both will find all faces in the photo, then using the alpha composite method, place the sparkles over all the faces they find, then paste the new face over the old one and save the new picture. If no faces are found, it simnply superimposes the sparkles over the entire image. While HAAR is inferior to DNN, I saw no real reason to remove it, and decided to surface the effect to the user as the `less accurate` effect options. Once these were successful, adding the googly eye effect to target a smaller area was a simple extension of the principal.

This was obviously the most fun part of the application, and the room for expansion was fairly clear. First, there was the prospect of using better algorithms. While this would have been fun, and in line with my interests, it was certainly out of scope for the project (as well as the job, at least during the intiial build out). I have some comments in the code itself containing my thoughts on how to enhance the accuracy of the facial recognition. The second improvement would have been allowing users to add their own custom effects. I have a pretty good idea of how this can be done, as all the pieces needed to implement it already exist within the application. That said, doing this would not have been trivial, so I elected to pass on its actual implementation.

The final element of the project was the devops. This proved to be the most troublesome aspect. At my last firm, I put a lot of effort into using kubernetes only to end up frustrating and nearly fail the project altogether. This time, I opeted for a simpler route; first, I would get the product working locally, then I would concern myself with its deployment. This overall proved an effective strategy, as the google app engine allowed for easy hosting of the front and back end, as well as simple communication between the two. I was also able to use a cloud SQL instance, obviating the need for managing my own containerized Postgres incidence. However, my approach did come with a downside; when developing locally, I leveraged my local filesystem for storing the images. This did not work on the cloud. I spent a decent amount of time deriving a methodology for serving the file binary data as strings to the clinet, then converting them to blobs and displaying them, only to realize that this methodology would not work in the production context. This forced me to go back to the drawing board, rip up what I had and implement the cloud storage method currently present. While I had an inkling this would happen, I decided to cross that bridge when I got to it; had I been cognizant of this earlier, I could have taken a cloud-first development approach which would have likely saved time (time which in turn could have been spent smoothing out some of the rough edges mentioned in these write ups). Live and learn I suppose.